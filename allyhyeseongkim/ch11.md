## Chapter 11. 쿠버네티스 내부 이해

### 1. 쿠버네티스 아키텍처
> 각 구성요소가 개별 프로세스로 동작하며 사진과 같은 의존성을 가진다.
> - API server를 통해 간접적으로 etcd에 접근함 → 저장소와의 통신을 API server에 위임(abstraction), validation, 낙관적 lock
<img width="500" src="https://github.com/user-attachments/assets/dee011b5-b9e0-43c1-a0fd-74851b43c8de">

- control plane: 클러스터의 상태 저장 및 관리함. 여러 개의 서버 사이에 분리될 수 있다(high availability (HA), 고가용성)
  - etcd 분산 스토리지: 병렬 처리 O. 클러스터의 정보와 메타데이터를 저장하는 유일한 저장소(fast, distributed, consistent key-value store)
    - distributed: HA를 위해 여러개 생성 가능
  - API server: 병렬 처리 O. 기본적인 CRUD interface 제공 → RESTful API로 클러스터의 상태를 조회하거나 수정할 수 있음 & 정보를 etcd에 저장(validation, 동시성)
  - scheduler: 병렬 처리 X. 나머지 작업은 standby 상태. API server에 요청을 보내 pod definition 수정 → kubelet이 watch하다가 pod가 schedule 되었음을 notify & pod 실행
  - contoller manager: 병렬 처리 X. 나머지 작업은 standby 상태
    - replicaset을 관리하거나 service endpoint를 관리하기 위해 리소스 변경 정보를 API server를 통해 받아옴
- worker node: 실제로 컨테이너를 동작하게 함
  - kubelet: 시스템에서 실행. 다른 컴포넌트들은 kubelet이 pod 형태로 실행함(control plane의 컴포넌트들은 시스템에서 직접 실행할 수도 있음)
  - kube-proxy
  - contoller runtime: ex. Docker
- add-on componenet
  - kubernetes DNS server
  - dashboard
  - ingress controller
  - heapster: 14장
  - CNI (Container Network Interface)

#### etcd
- 리소스 저장 방식
  - v2: key를 계층적으로 저장하여 key-value pair를 파일 시스템처러 관리(key는 다른 key를 포함하는 폴더이거나 value를 가짐)
  - v3: 폴더 지원 X. key의 형태는 유지 & '/'를 포함 → 폴더처럼 계층적으로 나뉘어 있다고 볼 수 있음
- consistent 업데이트: 낙관적 lock
  - 데이터에 lock을 걸어 read/write를 제한하는 것이 아닌 데이터의 버전을 추가하는 방식
  - 클라이언트가 데이터를 수정하고자 할 때 읽을 때와 쓸 때의 버전을 비교하여 다르면 업데이트 기각 & 클라이어트 업데이트 재시도(`metadata.resourceVersion` 필드를 API server에 업데이트 요청과 전달)
- 동기화: HA를 위해 etcd가 여러 개인 경우. RAFT 알고리즘(다수가 동의해야 다음 상태로 나아감)을 사용하여 etcd 간의 상태를 동기화 함 → etcd의 개수는 홀수가 좋다.
  <img width="500" src="https://github.com/user-attachments/assets/1f72676a-c026-4a29-afb2-507febd8c15e">

#### API server
<img width="500" src="https://github.com/user-attachments/assets/94d06680-a27e-4864-8376-ccc5b2eaa94e">
- API server 플러그인
  - 인증 플러그인: HTTP 요청 헤더에서 사용자 이름, 아이디, 그룹 정보 추출
  - 권한 승인 플러그인: 사용자가 요청된 액션을 수행할 수 있는지 결정
  - 승인 제어 플러그인: 요청대로 리소스 수정
- API server에서 요청을 받았을 때 flow
  1. 요청을 보낸 사람을 확인함(내부 authentication plugin 사용. HTTP 요청 분석)
  2. 해당 사용자가 요청의 내용을 실제로 수행할 수 있는지 확인(내부 authorization plugin 사용)
  3. 리소스 CUD 요청일 경우 Admission Control로 요청 전달(내부 plugin 사용. 요청의 리소스 spec에서 누락된 field 값을 채워주거나 다른 리소스 값을 수정하거나 요청 기각)
  4. validation & etcd에 저장하여 클라이언트에 응답 전달
  <img width="500" src="https://github.com/user-attachments/assets/0db6ea53-405a-4287-8680-ccdc2391b767">

- API server가 클라이언트에 리소스 변화(CUD)를 notify 하는 방법
  1. 클라이언트가 API server에 HTTP 연결
  2. 요청한(watch) 리소스의 변경 사항 발생 시 모든 클라이언트에 수정 내역 전달
 
#### Scheduler
- 노드를 고르는 방법: Default scheduling algorithm
  1. scheduling 가능한 노드 리스트 만들기
  2. 가장 적합한 노드를 고르고, 여러개이면 round-robin
<img width="500" src="https://github.com/user-attachments/assets/51de8f29-403d-48ca-890b-836070b3e836">

- 적합한 노드를 고르는 방법
  1. od 가 요구하는 하드웨어 리소스가 노드에 충분한가?
  2. 노드에 리소스가 거의 바닥나지는 않았는지?
  3. Pod 에서 특정한 노드로의 scheduling 을 요청하지는 않았는지?
  4. Node selector label 이 맞는지?
  5. Pod 가 특정 포트로 요청을 받는다면 해당 포트가 노드에서 이미 bind 되어 있지는 않은지?
  6. Pod 가 요구하는 volume 이 이 노드에서 mount 될 수 있는지?
  7. Pod 에 node affinity/anti-affinity 설정이 있는지?
