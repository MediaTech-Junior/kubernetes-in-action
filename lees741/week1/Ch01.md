# Ch01. 쿠버네티스 소개
> 쿠버네티스는 하드웨어 인프라를 추상화하고 데이터센터 전체를 하나의 거대한 컴퓨팅 리소스로 제공한다.

모놀리스 레거시 애플리케이션에서 점차 마이크로서비스 아키텍쳐 환경으로 전환됨에 따라 시스템 구성, 관리 및 유지가 어려워졌다.
따라서 쿠버네티스가 등장했고 시스템 관리자는 애플리케이션 감독 대신 쿠버네티스와 나머지 인프라 감독으로 관심이 바뀌었다.

#### Kubernetes 발음
[쿠버네티스 발음과 관련된 이슈](https://github.com/kubernetes/kubernetes/issues//44308)

한글화팀에서는 쿠버네티스(Koo-ber-netties)로 합의

## 1.1 쿠버네티스와 같은 시스템이 필요한 이유
### 1.1.1 모놀리스(Monolith) 애플리케이션에서 마이크로서비스로 전환
모놀리스 애플리케이션은 일부분이 변경되더라도 전체 애플리케이션을 재배포해야 하며, 점점 구성 요소 간의 상호의존성이 커져 시스템 복잡성이 증가하고 품질이 저하된다.

또한, 애플리케이션을 실행하는데 매우 강력한 서버가 필요하고 확장할 때에도 어려움이 있다.

#### 마이크로서비스로 애플리케이션 분할
이런 저런 복잡한 문제를 가지는 모놀리스 애플리케이션을 마이크로서비스라는 작은 구성 요소로 쪼개야 한다.
각 마이크로서비스는 API로 다른 마이크로서비스와 통신한다.

일반적으로 RESTful API를 제공하는 HTTP 동기 프로토콜을 사용한다.
API가 변경되지 않거나 이전 버전과 호환되는 방식으로 변경됐다면 다른 서비스를 변경하거나 재배포하지 않아도 된다는 장점이 있다.

#### 마이크로서비스 확장
모놀리스 시스템과 달리 마이크로서비스 확장은 각 구성 요소별로 수행되므로 리소스가 더 필요한 서비스만 별도로 확장 가능하다.

#### 마이크로서비스 배포
구성 요소가 적을 때는 문제가 되지 않지만, 구성 요소가 많아지면 배포 조합의 수뿐만 아니라 서비스 간의 상호종속성이 훨씬 더 복잡해지므로 관리가 점점 어려워진다.

또한 마이크로서비스는 여러 시스템에 분산돼 있기 때문에 실행 호출을 디버그하고 추적하기 어렵다.
이런 문제는 현재 `Zipkin`, [`Pinpoint`](https://github.com/pinpoint-apm/pinpoint)와 같은 분산 추적 시스템으로 해결한다.

## 1.2 컨테이너 기술 소개
> 쿠버네티스는 애플리케이션을 격리하는 기능을 제공하기 위해 리눅스 컨테이너 기술을 사용

### 1.2.1 컨테이너 이해
동일한 머신에서 실행되는 서로 다른 서비스가 서로 다른 혹은 상충될 수 있는 라이브러리 버전을 필요로 할 수 있다.
각 서비스마다 가상머신을 통해 고유한 운영체제 인스턴스를 제공할 수도 있다.
하지만, 서비스가 점점 많아지기 시작하면 하드웨어 리소스 & 이를 관리하기 위한 인적 자원이 낭비된다.

#### 컨테이너와 가상머신 비교
개발자들은 가상머신 대신 리눅스 컨테이너 기술에 눈을 돌렸다. 동일한 호스트 시스템에서 실행되고 가상머신보다 오버헤드가 훨씬 적다.

| 기술   | 특징                                |
|------|-----------------------------------|
| 가상머신 | 서비스 프로세스뿐만 아니라 시스템 프로세스를 실행해야 함   |
| 컨테이너 | 호스트 OS에서 실행, 애플리케이션이 소비하는 리소스만 사용 |

컨테이너는 서로 다른 앱도 모두 동일한 커널을 호출함으로 보안 위험이 발생할 수 있다.

ex. [`privileged container escape`](https://brunch.co.kr/@marload/13)

#### 컨테이너 격리를 가능하게 하는 메커니즘 소개
1. 리눅스 네임스페이스로 각 프로세스가 시스템에 대한 독립된 뷰만 보도록 한다.
   * 리눅스에서 추가 네임스페이스를 생성하고 리소스를 구성할 수 있다.
   * 프로세스는 동일한 네임스페이스 내의 리소스만 볼 수 있다.
   * 프로세스는 여러 네임스페이스에 속할 수도 있다.
2. 리눅스 컨트롤 그룹(`cgroups`)으로 프로세스가 사용할 수 있는 리소스 양을 제한한다.

### 1.2.2 도커 컨테이너 플랫폼 소개
> 컨테이너 기술은 오랫동안 사용돼 왔지만 도커 컨테이너 플랫폼의 등장으로 더 널리 알려지게 됐다.

도커로 패키징된 애플리케이션을 실행하면 함께 제공된 파일시스템을 그대로 볼 수 있다.
도커 기반 컨테이너 이미지는 가상머신 이미지와 다르게 재사용될 수 있는 레이어로 구성돼 있다.

#### 도커 개념 이해
도커는 애플리케이션을 전체 환경과 함께 패키징할 수 있다.
ex. 라이브러리, 운영체제 파일시스템 등

또한, 이 패키지를 중앙 저장소([Docker Hub](https://hub.docker.com))로 전송 가능하며, 도커를 실행하는 모든 컴퓨터에 전송할 수 있다.

###### 도커의 세 가지 주요 개념
* 이미지: 애플리케이션과 환경을 패키징한 것. 파일시스템, 실행파일 경로 등의 메타데이터도 포함
* 레지스트리: 도커 이미지를 저장하고 공유할 수 있는 저장소.
* 컨테이너: 도커 이미지에서 생성된 리눅스 컨테이너.

#### 도커 이미지의 빌드, 배포, 실행
개발자가 도커 이미지를 만들고 레지스트리로 푸시하면, 다른 사람들이 
각자의 환경에 이미지를 가져와 실행할 수 있다.
도커는 이미지를 기반으로 격리된 컨테이너를 생성하고 지정된 바이너리 실행파일을 실행한다.

#### 이미지 레이어의 이해
> 각 컨테이너는 격리된 자체 파일시스템이 있는데 같은 파일시스템을 사용하는 컨테이너는 파일시스템을 공유한다.

모든 도커 이미지는 다른 이미지 위에 빌드되고 두 개의 다른 이미지는 기본 이미지로 동일한 부모 이미지를 사용할 수 있으므로 다른 이미지에 동일한 레이어가 포함될 수 있다.

각 레이어는 동일한 호스트에 한 번만 저장되기 때문에 네트워크와 스토리지 공간을 효율적으로 사용하도록 도와준다.

동일한 레이어를 기반으로 한 두 개의 이미지에서 생성한 두 개의 컨테이너는 동일한 파일을 읽을 수 있지만 여전히 격리돼 있다.

#### 컨테이너 이미지의 제한적인 이식성 이해
호스트 OS의 커널을 사용하기 때문에 특정 하드웨어 아키텍처용으로 만들어진 컨테이너는 해당 아키텍처 시스템에서만 실행될 수 있다.

예를 들어, x86 아키텍처용으로 만들어진 컨테이너 애플리케이션을 ARM 기반 컴퓨터에서 도커가 실행된다고 컨테이너화할 수 없다.

## 1.3 쿠버네티스 소개
> 구글은 전 세계적으로 수십만 대의 서버를 운영하는 기업으로 엄청난 규모의 배포 관리를 처리해야 했다.
> 이로 인해 수천 개의 소프트웨어 구성 요소를 관리할 수 있는 솔루션을 개발해야만 했다.

### 1.3.1 쿠버네티스의 기원
구글은 `Borg`(이후 `Omega`로 바뀐 시스템)라는 내부 시스템을 개발해 애플리케이션 개발자와 시스템 관리자가 서비스를 관리하는 데 도움을 줬다.

이 시스템을 10년 동안 비밀로 유지하다가 2014년 오픈소스 시스템인 쿠버네티스를 출시했다.

### 1.3.2 넓은 시각으로 쿠버네티스 바라보기
> 쿠버네티스는 컨테이너화된 애플리케이션을 쉽게 배포하고 관리할 수 있게 해주는 소프트웨어 시스템

클러스터에 노드가 몇 개가 있든 쿠버네티스에 애플리케이션을 배포하는 것은 항상 동일하다.
**즉, 애플리케이션 관리가 정말 쉽다!**

#### 쿠버네티스 핵심 이해
개발자가 애플리케이션 매니페스트를 마스터에 선언하면 쿠버네티스는 해당 애플리케이션을 워커 노드 클러스터에 배포한다.

쿠버네티스가 알아서 해주기 때문에 구성 요소가 어떤 노드에 배포되는지는 개발자나 시스템 관리자에게 중요하지 않다.

#### 개발자가 애플리케이션 핵심 기능에 집중할 수 있도록 지원
우리 같은 애플리케이션 개발자가 특정 인프라 관련 서비스를 애플리케이션에 구현하지 않아도 된다.

ex. 서비스 디스커버리, 스케일링, 로드밸런싱, 자가 치유, 리더 선출 등

#### 운영 팀이 효과적으로 리소스를 활용할 수 있도록 지원
애플리케이션은 어떤 노드에서 실행되든 상관 없기 때문에 언제든지 애플리케이션을 재배치하고 조합할 수 있다.

### 1.3.3 쿠버네티스 클러스터 아키텍처 이해
> 하드웨어 수준에서 쿠버네티스 클러스터는 여러 노드로 구성되며 두 가지 유형으로 나눌 수 있다.

* 마스터 노드: 전체 쿠버네티스 시스템을 제어하고 관리하는 쿠버네티스 컨트롤 플레인 실행
* 워커 노드: 실제 배포되는 컨테이너 애플리케이션을 실행

#### 컨트롤 플레인
> 클러스터를 제어하고 작동시킨다.
> 하나의 마스터 노드에서 실행하거나 여러 노드로 분할되고 복제돼 고가용성 보장할 수 있는 여러 구성요소로 구성된다.

* 쿠버네티스 API 서버: 사용자, 컨트롤 플레인 구성 요소와 통신
* 스케줄러: 애플리케이션 배포 담당 (애플리케이션의 배포 가능한 각 구성 요소를 워커 노드에 할당)
* 컨트롤러 매니저: 구성 요소 복제본, 워커 노드 추적, 노드 장애 처리 등 클러스터단 기능 수행
* `etcd`: 클러스터 구성을 지속적으로 저장하는 신뢰할 수 있는 분산 데이터 저장소

#### 노드
> 워커 노드는 컨테이너화된 애플리케이션을 실행하는 시스템.

애플리케이션을 실행하고 모니터링하며 다음 구성 요소를 통해 애플리케이션에 서비스를 제공한다.
* 컨테이너 런타임: 컨테이너를 실행 (도커)
* `kubelet`: API 서버와 통신하고 노드의 컨테이너 관리
* `kube-proxy`: 애플리케이션 구성 요소 간에 네트워크 트래픽을 로드밸런싱

### 1.3.4 쿠버네티스에서 애플리케이션 실행
> 애플리케이션을 하나 이상의 컨테이너 이미지로 패키징하고 이미지 레지스트리로 푸시한 다음 쿠버네티스 API 서버에 애플리케이션 디스크립션을 게시해야 한다.

#### 디스크립션으로 컨테이너를 실행하는 방법 이해
API 서버가 애플리케이션 디스크립션을 처리할 때 스케줄러는 워커 노드에 컨테이너를 할당한다.
그러면 해당 노드의 `kubelet`은 컨테이너 런타임에 필요한 이미지를 가져와 컨테이너 실행하도록 지시한다.

#### 실행된 컨테이너 유지
애플리케이션이 실행되면 쿠버네티스는 애플리케이션 상태가 디스크립션과 일치하는지 지속적으로 모니터링한다.
프로세스가 중단되거나 응답이 중지될 때와 같이 인스턴스가 제대로 작동하지 않으면 쿠버네티스가 자동으로 재시작한다.

마찬가지로 워커 노드 전체가 종료되거나 액세스할 수 없게 되면 이 노드에서 실행 중인 모든 컨테이너를 새로 스케줄링한다.

#### 복제본 수 스케일링
복제본 수를 늘릴지 줄일지 직접 결정할 수 있으며, 최적의 복제본 수를 결정하는 작업을 쿠버네티스에 맡길 수도 있다. (오토 스케일링)

#### 이동한 애플리케이션에 접근하기
쿠버네티스에서 컨테이너는 재시작될 수도 있고 다른 노드로 이동할 수도 있다.
이 경우 외부 클라이언트나 다른 컨테이너는 어떻게 이동한 컨테이너에 접근할 수 있을까?

쿠버네티스는 동일한 서비스를 제공하는 컨테이너를 하나의 고정 IP 주소로 노출하고 클러스터에서 실행 중인 모든 애플리케이션에 노출한다.
클라이언트는 DNS로 서비스 IP를 조회할 수도 있다.

`kube-proxy`는 동일한 서비스를 제공하는 모든 컨테이너에 서비스 연결이 되도록 로드밸런싱한다.

**즉, 서비스 IP는 일정하게 유지되므로 컨테이너가 클러스터 내에서 이동하더라도 클라이언트가 접근하는 데 문제가 없다!**

### 1.3.5 쿠버네티스 사용의 장점
> 모든 서버에 쿠버네티스가 설치되어 있다면 운영팀은 애플리케이션 배포를 처리할 필요가 없다.

#### 하드웨어 활용도 높이기
쿠버네티스가 알아서 최적의 노드에서 애플리케이션 컨테이너를 실행시켜 주기 때문에 노드의 하드웨어 리소스를 최대한 활용할 수 있다.
애플리케이션 구성 요소와 배포할 서버 노드가 많은 경우 사람이 수동으로 최적의 옵션을 찾는 것은 매우 힘들 것이다.

#### 상태 확인과 자가 치유
서버 장애 발생 시 충분한 예비 자원이 있는 경우 쿠버네티스가 알아서 재실행해주기 때문에 **새벽 3시**에 발생한 장애에 즉시 대응할 필요가 없다.

#### 오토스케일링
급격한 부하 급증에 대응하기 위해 개별 애플리케이션의 부하를 지속적으로 모니터링할 필요가 없다.
쿠버네티스는 리소스를 모니터링하고 인스턴스 수를 자동으로 조정할 수 있기 때문이다.